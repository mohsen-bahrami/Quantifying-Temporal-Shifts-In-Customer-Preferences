{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Filtering weekly foot traffic information from the complete datasets posted on SafeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '2021data' # We do not upload this data because the information is raw from SafeGraph\n",
    "all_file_paths = [os.path.join(path, name) for path, subdirs, files in os.walk(root) for name in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_2021 = [i for i in all_file_paths if '.csv.gz' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_path_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(pd.read_csv('data/1_data_for_extracting_information/all_info_before_aggregation.csv')['safegraph_place_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_path = 'core_poi-part' # We do not upload this data because the information is raw from SafeGraph\n",
    "core_data = []\n",
    "for i in range(1,6):\n",
    "    core_data.append(pd.read_csv(core_path + str(i) + '.csv.gz', compression='gzip'))\n",
    "core_df = pd.concat(core_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "placekeys = core_df[core_df['safegraph_place_id'].isin(ids)]['placekey'].unique().tolist()\n",
    "len(placekeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_obs_weekly(data_path):\n",
    "    df = pd.read_csv(data_path, compression='gzip')\n",
    "    return df[df['placekey'].isin(placekeys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  finished\n",
      "1  finished\n",
      "2  finished\n",
      "3  finished\n",
      "4  finished\n",
      "5  finished\n",
      "6  finished\n",
      "7  finished\n",
      "8  finished\n",
      "9  finished\n",
      "10  finished\n",
      "11  finished\n",
      "12  finished\n",
      "13  finished\n",
      "14  finished\n",
      "15  finished\n",
      "16  finished\n",
      "17  finished\n",
      "18  finished\n",
      "19  finished\n",
      "20  finished\n",
      "21  finished\n",
      "22  finished\n",
      "23  finished\n",
      "24  finished\n",
      "25  finished\n",
      "26  finished\n",
      "27  finished\n",
      "28  finished\n",
      "29  finished\n",
      "30  finished\n",
      "31  finished\n",
      "32  finished\n",
      "33  finished\n",
      "34  finished\n",
      "35  finished\n",
      "36  finished\n",
      "37  finished\n",
      "38  finished\n",
      "39  finished\n",
      "40  finished\n",
      "41  finished\n",
      "42  finished\n",
      "43  finished\n",
      "44  finished\n",
      "45  finished\n",
      "46  finished\n",
      "47  finished\n",
      "48  finished\n",
      "49  finished\n",
      "50  finished\n",
      "51  finished\n",
      "52  finished\n",
      "53  finished\n",
      "54  finished\n",
      "55  finished\n",
      "56  finished\n",
      "57  finished\n",
      "58  finished\n",
      "59  finished\n",
      "60  finished\n",
      "61  finished\n",
      "62  finished\n",
      "63  finished\n",
      "64  finished\n",
      "65  finished\n",
      "66  finished\n",
      "67  finished\n",
      "68  finished\n",
      "69  finished\n",
      "70  finished\n",
      "71  finished\n",
      "72  finished\n",
      "73  finished\n",
      "74  finished\n",
      "75  finished\n",
      "76  finished\n",
      "77  finished\n",
      "78  finished\n",
      "79  finished\n",
      "80  finished\n",
      "81  finished\n",
      "82  finished\n",
      "83  finished\n",
      "84  finished\n",
      "85  finished\n",
      "86  finished\n",
      "87  finished\n",
      "88  finished\n",
      "89  finished\n",
      "90  finished\n",
      "91  finished\n",
      "92  finished\n",
      "93  finished\n",
      "94  finished\n",
      "95  finished\n",
      "96  finished\n",
      "97  finished\n",
      "98  finished\n",
      "99  finished\n",
      "100  finished\n",
      "101  finished\n",
      "102  finished\n",
      "103  finished\n",
      "104  finished\n",
      "105  finished\n",
      "106  finished\n",
      "107  finished\n",
      "108  finished\n",
      "109  finished\n",
      "110  finished\n",
      "111  finished\n",
      "112  finished\n",
      "113  finished\n",
      "114  finished\n",
      "115  finished\n",
      "116  finished\n",
      "117  finished\n",
      "118  finished\n",
      "119  finished\n",
      "120  finished\n",
      "121  finished\n",
      "122  finished\n",
      "123  finished\n",
      "124  finished\n",
      "125  finished\n",
      "126  finished\n",
      "127  finished\n",
      "128  finished\n",
      "129  finished\n",
      "130  finished\n",
      "131  finished\n",
      "132  finished\n",
      "133  finished\n",
      "134  finished\n",
      "135  finished\n",
      "136  finished\n",
      "137  finished\n",
      "138  finished\n",
      "139  finished\n",
      "140  finished\n",
      "141  finished\n",
      "142  finished\n",
      "143  finished\n",
      "144  finished\n",
      "145  finished\n",
      "146  finished\n",
      "147  finished\n",
      "148  finished\n",
      "149  finished\n",
      "150  finished\n",
      "151  finished\n",
      "152  finished\n",
      "153  finished\n",
      "154  finished\n",
      "155  finished\n",
      "156  finished\n",
      "157  finished\n",
      "158  finished\n",
      "159  finished\n",
      "160  finished\n",
      "161  finished\n",
      "162  finished\n",
      "163  finished\n",
      "164  finished\n",
      "165  finished\n",
      "166  finished\n",
      "167  finished\n",
      "168  finished\n",
      "169  finished\n",
      "170  finished\n",
      "171  finished\n",
      "172  finished\n",
      "173  finished\n",
      "174  finished\n",
      "175  finished\n",
      "176  finished\n",
      "177  finished\n",
      "178  finished\n",
      "179  finished\n",
      "180  finished\n",
      "181  finished\n",
      "182  finished\n",
      "183  finished\n",
      "184  finished\n",
      "185  finished\n",
      "186  finished\n",
      "187  finished\n",
      "188  finished\n",
      "189  finished\n",
      "190  finished\n",
      "191  finished\n"
     ]
    }
   ],
   "source": [
    "filtered_abs_path = '2021_filtered_data' # We do not upload this data because the information is raw from SafeGraph\n",
    "for i,cont in enumerate(file_path_2021):\n",
    "    try:\n",
    "        temp_df = get_good_obs_weekly(cont)\n",
    "        if len(temp_df) > 0:\n",
    "            temp_df.to_csv(filtered_abs_path+'/'+str(i)+ '.csv', index = False)\n",
    "    except:\n",
    "        pass\n",
    "    print(i,' finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = os.listdir(filtered_abs_path)\n",
    "dfs = [filtered_abs_path + '/' + i for i in dfs if '.csv' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pd.read_csv(i) for i in dfs]\n",
    "nyc_data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_data = nyc_data.sort_values(by = ['placekey', 'date_range_start', \n",
    "                                      'date_range_end', 'normalized_visits_by_region_naics_visits'],\n",
    "                                ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7298, 34)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_data_dropped = nyc_data.drop_duplicates(subset = ['placekey', 'date_range_start'])\n",
    "nyc_data_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_data_dropped.to_csv('NYC_weekly_traffic_data_2021.csv', \n",
    "                        index = False)# We do not upload this data because the information is raw from SafeGraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
