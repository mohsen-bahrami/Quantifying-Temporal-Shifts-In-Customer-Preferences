{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Filtering weekly foot traffic information from the complete datasets posted on SafeGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'raw_data' # We do not upload this data because the information is raw from SafeGraph\n",
    "folder_list = os.listdir(path)\n",
    "folder_list = [path+'/'+i for i in folder_list if 'DS' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_2020 = []\n",
    "for f in folder_list:\n",
    "    files_temp = os.listdir(f)\n",
    "    files_temp = [f+'/'+i for i in files_temp if 'DS' not in i if '_patterns' not in i]\n",
    "    file_path_2020.extend(files_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_path_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(pd.read_csv('all_info_before_aggregation.csv')['safegraph_place_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_good_obs_weekly(data_path):\n",
    "    df = pd.read_csv(data_path, compression='gzip')\n",
    "    return df[df['safegraph_place_id'].isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  finished\n",
      "1  finished\n",
      "2  finished\n",
      "3  finished\n",
      "4  finished\n",
      "5  finished\n",
      "6  finished\n",
      "7  finished\n",
      "8  finished\n",
      "9  finished\n",
      "10  finished\n",
      "11  finished\n",
      "12  finished\n",
      "13  finished\n",
      "14  finished\n",
      "15  finished\n",
      "16  finished\n",
      "17  finished\n",
      "18  finished\n",
      "19  finished\n",
      "20  finished\n",
      "21  finished\n",
      "22  finished\n",
      "23  finished\n",
      "24  finished\n",
      "25  finished\n",
      "26  finished\n",
      "27  finished\n",
      "28  finished\n",
      "29  finished\n",
      "30  finished\n",
      "31  finished\n",
      "32  finished\n",
      "33  finished\n",
      "34  finished\n",
      "35  finished\n",
      "36  finished\n",
      "37  finished\n",
      "38  finished\n",
      "39  finished\n",
      "40  finished\n",
      "41  finished\n",
      "42  finished\n",
      "43  finished\n",
      "44  finished\n",
      "45  finished\n",
      "46  finished\n",
      "47  finished\n",
      "48  finished\n",
      "49  finished\n",
      "50  finished\n",
      "51  finished\n",
      "52  finished\n",
      "53  finished\n",
      "54  finished\n",
      "55  finished\n",
      "56  finished\n",
      "57  finished\n",
      "58  finished\n",
      "59  finished\n",
      "60  finished\n",
      "61  finished\n",
      "62  finished\n",
      "63  finished\n",
      "64  finished\n",
      "65  finished\n",
      "66  finished\n",
      "67  finished\n",
      "68  finished\n",
      "69  finished\n",
      "70  finished\n",
      "71  finished\n",
      "72  finished\n",
      "73  finished\n",
      "74  finished\n",
      "75  finished\n",
      "76  finished\n",
      "77  finished\n",
      "78  finished\n",
      "79  finished\n",
      "80  finished\n",
      "81  finished\n",
      "82  finished\n",
      "83  finished\n",
      "84  finished\n",
      "85  finished\n",
      "86  finished\n",
      "87  finished\n",
      "88  finished\n",
      "89  finished\n",
      "90  finished\n",
      "91  finished\n",
      "92  finished\n",
      "93  finished\n",
      "94  finished\n",
      "95  finished\n",
      "96  finished\n",
      "97  finished\n",
      "98  finished\n",
      "99  finished\n",
      "100  finished\n",
      "101  finished\n",
      "102  finished\n",
      "103  finished\n",
      "104  finished\n",
      "105  finished\n",
      "106  finished\n",
      "107  finished\n",
      "108  finished\n",
      "109  finished\n",
      "110  finished\n",
      "111  finished\n",
      "112  finished\n",
      "113  finished\n",
      "114  finished\n",
      "115  finished\n",
      "116  finished\n",
      "117  finished\n",
      "118  finished\n",
      "119  finished\n",
      "120  finished\n",
      "121  finished\n",
      "122  finished\n",
      "123  finished\n",
      "124  finished\n",
      "125  finished\n",
      "126  finished\n",
      "127  finished\n",
      "128  finished\n",
      "129  finished\n",
      "130  finished\n",
      "131  finished\n",
      "132  finished\n",
      "133  finished\n",
      "134  finished\n",
      "135  finished\n",
      "136  finished\n",
      "137  finished\n",
      "138  finished\n",
      "139  finished\n",
      "140  finished\n",
      "141  finished\n",
      "142  finished\n",
      "143  finished\n",
      "144  finished\n",
      "145  finished\n",
      "146  finished\n",
      "147  finished\n",
      "148  finished\n",
      "149  finished\n",
      "150  finished\n",
      "151  finished\n",
      "152  finished\n",
      "153  finished\n",
      "154  finished\n",
      "155  finished\n",
      "156  finished\n",
      "157  finished\n",
      "158  finished\n",
      "159  finished\n",
      "160  finished\n",
      "161  finished\n",
      "162  finished\n",
      "163  finished\n",
      "164  finished\n",
      "165  finished\n",
      "166  finished\n",
      "167  finished\n",
      "168  finished\n",
      "169  finished\n",
      "170  finished\n",
      "171  finished\n",
      "172  finished\n",
      "173  finished\n",
      "174  finished\n",
      "175  finished\n",
      "176  finished\n",
      "177  finished\n",
      "178  finished\n",
      "179  finished\n",
      "180  finished\n",
      "181  finished\n",
      "182  finished\n",
      "183  finished\n",
      "184  finished\n",
      "185  finished\n",
      "186  finished\n",
      "187  finished\n",
      "188  finished\n",
      "189  finished\n",
      "190  finished\n",
      "191  finished\n",
      "192  finished\n",
      "193  finished\n",
      "194  finished\n",
      "195  finished\n",
      "196  finished\n",
      "197  finished\n",
      "198  finished\n",
      "199  finished\n",
      "200  finished\n",
      "201  finished\n",
      "202  finished\n",
      "203  finished\n",
      "204  finished\n",
      "205  finished\n",
      "206  finished\n",
      "207  finished\n",
      "208  finished\n",
      "209  finished\n",
      "210  finished\n",
      "211  finished\n",
      "212  finished\n",
      "213  finished\n",
      "214  finished\n",
      "215  finished\n",
      "216  finished\n",
      "217  finished\n",
      "218  finished\n",
      "219  finished\n",
      "220  finished\n",
      "221  finished\n",
      "222  finished\n",
      "223  finished\n"
     ]
    }
   ],
   "source": [
    "filtered_abs_path = 'filtered_data' # We do not upload this data because the information is raw from SafeGraph\n",
    "for i,cont in enumerate(file_path_2020):\n",
    "    temp_df = get_good_obs_weekly(cont)\n",
    "    print(i,' finished')\n",
    "    if len(temp_df) > 0:\n",
    "        temp_df.to_csv(filtered_abs_path+'/'+str(i)+ '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = os.listdir(filtered_abs_path)\n",
    "dfs = [filtered_abs_path + '/' + i for i in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pd.read_csv(i) for i in dfs]\n",
    "nyc_data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_data.to_csv('NYC_weekly_traffic_data_2020.csv', \n",
    "                index = False) # We do not upload this data because the information is raw from SafeGraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
